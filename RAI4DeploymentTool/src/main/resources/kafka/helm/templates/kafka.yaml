apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: {{ .Values.name }}
spec:
  selector:
    matchLabels:
      app: {{ .Values.name }}
  serviceName: {{ .Values.name }}-hs
  replicas: {{ .Values.replicaCount }}
  template:
    metadata:
      labels:
        app: {{ .Values.name }}
    spec:
      serviceAccountName: k8s-101-role
      initContainers:
      - name: kubectl
        image: bitnami/kubectl
        command: ['sh', '-c', 'external_ip=""; while [ -z $external_ip ]; do echo "Waiting for end point..."; external_ip=$(kubectl get svc kafka-svc -o jsonpath="{.status.loadBalancer.ingress[0].ip}"); [ -z "$external_ip" ] && sleep 10; done; echo "End point ready-" && echo $external_ip >> /shared/ip.txt;']
        volumeMounts:
        - name: shared-mount
          mountPath: /shared
      containers:
      - name: {{ .Values.name }}
        imagePullPolicy: {{ .Values.image.pullPolicy }}
        image: {{ .Values.image.repository }}:{{ .Values.image.tag }}
        command:
        - sh
        - -c
        - "exec kafka-server-start.sh /opt/kafka/config/server.properties --override broker.id=${HOSTNAME##*-} \
          --override listeners=INTERNAL://:9092,EXTERNAL://:9094  \
          --override advertised.listeners=INTERNAL://$(POD_NAME).{{ .Values.name }}-hs.default.svc.cluster.local:9092,EXTERNAL://$(cat /shared/ip.txt):9094 \
          --override listener.security.protocol.map=INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT \
          --override inter.broker.listener.name=INTERNAL \
          --override zookeeper.connect={{ .Values.zookeeperConnect }} \
          --override log.dir={{ .Values.logDir }} \
          --override auto.create.topics.enable={{ .Values.autoCreateTopicsEnable }} \
          --override auto.leader.rebalance.enable={{ .Values.autoLeaderRebalanceEnable }} \
          --override background.threads={{ .Values.backgroundThreads }} \
          --override compression.type={{ .Values.compressionType }} \
          --override delete.topic.enable={{ .Values.deleteTopicEnable }} \
          --override leader.imbalance.check.interval.seconds={{ .Values.leaderImbalanceCheckIntervalSeconds }} \
          --override leader.imbalance.per.broker.percentage={{ .Values.leaderImbalancePerBrokerPercentage }} \
          --override log.flush.interval.messages={{ .Values.logFlushIntervalMessages }} \
          --override log.flush.offset.checkpoint.interval.ms={{ .Values.logFlushOffsetCheckpointIntervalMs }} \
          --override log.flush.scheduler.interval.ms={{ .Values.logFlushSchedulerIntervalMs }} \
          --override log.retention.bytes={{ .Values.logRetentionBytes }} \
          --override log.retention.hours={{ .Values.logRetentionHours }} \
          --override log.roll.hours={{ .Values.logRollHours }} \
          --override log.roll.jitter.hours={{ .Values.logRollJitterHours }} \
          --override log.segment.bytes={{ .Values.logSegmentBytes }} \
          --override log.segment.delete.delay.ms={{ .Values.logSegmentDeleteDelayMs }} \
          --override message.max.bytes={{ .Values.messageMaxBytes }} \
          --override min.insync.replicas={{ .Values.minInsyncReplicas }} \
          --override num.io.threads={{ .Values.numIoThreads }} \
          --override num.network.threads={{ .Values.numNetworkThreads }} \
          --override num.recovery.threads.per.data.dir={{ .Values.numRecoveryThreadsPerDataDir }} \
          --override num.replica.fetchers={{ .Values.numReplicaFetchers }} \
          --override offset.metadata.max.bytes={{ .Values.offsetMetadataMaxBytes }} \
          --override offsets.commit.required.acks={{ .Values.offsetsCommitRequiredAcks }} \
          --override offsets.commit.timeout.ms={{ .Values.offsetsCommitTimeoutMs }} \
          --override offsets.load.buffer.size={{ .Values.offsetsLoadBufferSize }} \
          --override offsets.retention.check.interval.ms={{ .Values.offsetsRetentionCheckIntervalMs }} \
          --override offsets.retention.minutes={{ .Values.offsetsRetentionMinutes }} \
          --override offsets.topic.compression.codec={{ .Values.offsetsTopicCompressionCodec }} \
          --override offsets.topic.num.partitions={{ .Values.offsetsTopicNumPartitions }} \
          --override offsets.topic.replication.factor={{ .Values.offsetsTopicReplicationFactor }} \
          --override offsets.topic.segment.bytes={{ .Values.offsetsTopicSegmentBytes }} \
          --override queued.max.requests={{ .Values.queuedMaxRequests }} \
          --override quota.consumer.default={{ .Values.quotaConsumerDefault }} \
          --override quota.producer.default={{ .Values.quotaProducerDefault }} \
          --override replica.fetch.min.bytes={{ .Values.replicaFetchMinBytes }} \
          --override replica.fetch.wait.max.ms={{ .Values.replicaFetchWaitMaxMs }} \
          --override replica.high.watermark.checkpoint.interval.ms={{ .Values.replicaHighWatermarkCheckpointIntervalMs }} \
          --override replica.lag.time.max.ms={{ .Values.replicaLagTimeMaxMs }} \
          --override replica.socket.receive.buffer.bytes={{ .Values.replicaSocketReceiveBufferBytes }} \
          --override replica.socket.timeout.ms={{ .Values.replicaSocketTimeoutMs }} \
          --override request.timeout.ms={{ .Values.requestTimeoutMs }} \
          --override socket.receive.buffer.bytes={{ .Values.socketReceiveBufferBytes }} \
          --override socket.request.max.bytes={{ .Values.socketRequestMaxBytes }} \
          --override socket.send.buffer.bytes={{ .Values.socketSendBufferBytes }} \
          --override unclean.leader.election.enable={{ .Values.uncleanLeaderElectionEnable }} \
          --override zookeeper.session.timeout.ms={{ .Values.zookeeperSessionTimeoutMs }} \
          --override zookeeper.set.acl={{ .Values.zookeeperSetAcl }} \
          --override broker.id.generation.enable={{ .Values.brokerIdGenerationEnable }} \
          --override connections.max.idle.ms={{ .Values.connectionsMaxIdleMs }} \
          --override controlled.shutdown.enable={{ .Values.controlledShutdownEnable }} \
          --override controlled.shutdown.max.retries={{ .Values.controlledShutdownMaxRetries }} \
          --override controlled.shutdown.retry.backoff.ms={{ .Values.controlledShutdownRetryBackoffMs }} \
          --override controller.socket.timeout.ms={{ .Values.controllerSocketTimeoutMs }} \
          --override default.replication.factor={{ .Values.defaultReplicationFactor }} \
          --override fetch.purgatory.purge.interval.requests={{ .Values.fetchPurgatoryPurgeIntervalRequests }} \
          --override group.max.session.timeout.ms={{ .Values.groupMaxSessionTimeoutMs }} \
          --override group.min.session.timeout.ms={{ .Values.groupMinSessionTimeoutMs }} \
          --override inter.broker.protocol.version={{ .Values.interBrokerProtocolVersion }} \
          --override log.cleaner.backoff.ms={{ .Values.logCleanerBackoffMs }} \
          --override log.cleaner.dedupe.buffer.size={{ .Values.logCleanerDedupeBufferSize }} \
          --override log.cleaner.delete.retention.ms={{ .Values.logCleanerDeleteRetentionMs }} \
          --override log.cleaner.enable={{ .Values.logCleanerEnable }} \
          --override log.cleaner.io.buffer.load.factor={{ .Values.logCleanerIoBufferLoadFactor }} \
          --override log.cleaner.io.buffer.size={{ .Values.logCleanerIoBufferSize }} \
          --override log.cleaner.io.max.bytes.per.second={{ .Values.logCleanerIoMaxBytesPerSecond }} \
          --override log.cleaner.min.cleanable.ratio={{ .Values.logCleanerMinCleanableRatio }} \
          --override log.cleaner.min.compaction.lag.ms={{ .Values.logCleanerMinCompactionLagMs }} \
          --override log.cleaner.threads={{ .Values.logCleanerThreads }} \
          --override log.cleanup.policy={{ .Values.logCleanupPolicy }} \
          --override log.index.interval.bytes={{ .Values.logIndexIntervalBytes }} \
          --override log.index.size.max.bytes={{ .Values.logIndexSizeMaxBytes }} \
          --override log.message.timestamp.difference.max.ms={{ .Values.logMessageTimestampDifferenceMaxMs }} \
          --override log.message.timestamp.type={{ .Values.logMessageTimestampType }} \
          --override log.preallocate={{ .Values.logPreallocate }} \
          --override log.retention.check.interval.ms={{ .Values.logRetentionHours }} \
          --override max.connections.per.ip={{ .Values.maxConnectionsPerIp }} \
          --override num.partitions={{ .Values.numPartitions }} \
          --override producer.purgatory.purge.interval.requests={{ .Values.producerPurgatoryPurgeIntervalRequests }} \
          --override replica.fetch.backoff.ms={{ .Values.replicaFetchBackoffMs }} \
          --override replica.fetch.max.bytes={{ .Values.replicaFetchMaxBytes }} \
          --override replica.fetch.response.max.bytes={{ .Values.replicaFetchResponseMaxBytes }} \
          --override reserved.broker.max.id={{ .Values.reservedBrokerMaxId }} " 
        env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                fieldPath: metadata.name
        ports:
        - containerPort: {{ .Values.clientPort }}
          name: kafka
        volumeMounts:
        - name: datadir
          mountPath: /var/lib/kafka
        - name: shared-mount
          mountPath: /shared
      volumes:
        - name: shared-mount
          emptyDir: {}
  volumeClaimTemplates:
  - metadata:
      name: datadir
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 1Gi
